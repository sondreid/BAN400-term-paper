plot_title_size = 12,
base_size = 14,
axis_title_size = 12)
if (!is.na(ymin) | !is.na(ymax)){
plot <- plot + ylim(ymin, ymax)
}
plot <- plot +
facet_wrap(~agegroup, nrow = 1) # Wraps number of agegroups on a single row
ggsave(paste("../results/", filename))
return (ggplotly(plot))           # ggplotly for interactivity
}
"Plots all the agegroups in a country in single plots"
plotter <- function(df, gender = c("M", "F"), country){
for (agegroup in levels(df$agegroup)){
print(plotfunction_diff(df,
agevector = agegroup,
gendervector = gender,
country = country))
}
}
"Stores created plots in pdf-file"
plot_pdf <- function(filename, plot){
pdf(paste("../results/",filename), onefile = TRUE)
plotter(plot)
dev.off()
}
#### Total Data ----------------------------------------------------------------
"Totaldata is a dataframe which contains all the created data frames to
a consolidated data frame"
totaldata <- assembleAllData()
##### Test statistics-----------------------------------------------------------
"Is the difference in deaths and expected deaths statistically significant?"
"Function that conducts a two sided welch t.test to test whether 2020
deaths are statistically different than expected deaths. Compares x_mean and
y_mean to find out whether deaths are higher or lower. Tags the p.value along
with a string indicating whether it is above or below the estimated deaths, and
returns them as a list"
t_testFunc <- function(df,
agegroupvector = c("0-64", "65-79", "80-84", "85+"),
countryparam =? character ) {
testset <- df %>%
filter(country == countryparam,
agegroup %in% agegroupvector,
week >= 12) %>%
group_by(week) %>%
summarise(deaths = sum(deaths),
expected_deaths = sum(expected_deaths)) %>%
select(deaths,
expected_deaths)
t_test <- t.test(testset$deaths,
testset$expected_deaths,
alternative = "two.sided",
var.equal = FALSE)
# Determine whether the mean estimate mean deaths are higher or
# lower than the expected deaths
x_mean <- as.integer(t_test$estimate[1])
y_mean <- as.integer(t_test$estimate[2])
if (x_mean < y_mean) {return(list("Below", t_test$p.value)) }
else return(list("Above", t_test$p.value))
}
"Function that returns a string
Calls t_testFunc on a given country, uses totaldata as df as opposed to tabledata.
Returns a string based on the result from t_test_func."
tableTests <- function(country) {
test <- t_testFunc(totaldata,
agegroupvector = c("0-64", "65-79", "80-84", "85+"),
countryparam = country)
p.value <- test[[2]]
outputlist <- list(test[[1]], p.value)
if (p.value > 0.15) outputlist[[1]] <- "Normal"
else if (test[[1]] == "Above") {
if      (p.value < 0.025) outputlist[[1]] <- "Above ***"
else if (p.value < 0.05)  outputlist[[1]] <- "Above **"
else if (p.value < 0.15)  outputlist[[1]] <- "Above *"
}
else if (test[[1]] == "Below")  {
if      (p.value < 0.025) outputlist[[1]] <- "Below ***"
else if (p.value < 0.05)  outputlist[[1]] <- "Below **"
else if (p.value < 0.15)  outputlist[[1]] <- "Below *"
}
return (outputlist)
}
" Returns the first element of a list generated by tableTests func"
getTableTestFirst <- function(country) {
return (tableTests(country)[[1]])
}
getTableTestFirst <- Vectorize(getTableTestFirst)
" Returns the second element of a list generated by tableTests func"
getTableTestPvalue <- function(country) {
return (round(tableTests(country)[[2]], 4))
}
getTableTestPvalue <- Vectorize(getTableTestPvalue)
## Tables  ---------------------------------------------------------------------
totaldataFilter <- totaldata %>% filter(week >= 12)
shortTable_data <- totaldataFilter  %>%
group_by(country) %>%
summarise(excess_deaths = sum(excess_deaths)) %>%
## Max excess deaths per week
cbind(.,
totaldataFilter %>%
group_by(country, week) %>%
summarise(excess_deaths = sum(excess_deaths)) %>%
group_by(country) %>%
filter(excess_deaths == max(excess_deaths)) %>%
rename(max_deaths_perweek = excess_deaths )) %>%
select(-3) %>%
## Percentage above normal
cbind(.,
totaldataFilter %>% filter(week >= 12) %>%
group_by(country) %>%
summarise(percentage_above_normal = percent((
sum(deaths)/sum(expected_deaths)))) %>%
select(-country)) %>%
mutate(statistically_significant = getTableTestFirst(country),
p.value = getTableTestPvalue(country)) %>%
rename("Country"                          = country,
"Total Excess Deaths"              = excess_deaths,
"Highest Excess Deaths in a Week"  = max_deaths_perweek,
"Week: Highest Excess deaths"      = week,
"Percentage of Normal Deaths"      = percentage_above_normal,
"Statistically Significant"        = statistically_significant,
"P-value"                          = p.value)
longTable_data <- totaldata %>%
select(-year)
"Function that returns shortTableData using the formattable package"
shortTable <- function() {
lightred = "#ff7f7f"
outputTable <- formattable(shortTable_data, list(
"Total Excess Deaths"              = color_tile("white", lightred),
"Highest Excess Deaths in a Week"  = color_bar(lightred),
"Percentage of Normal Deaths"      = color_bar(lightred),
"Statistically Significant"        =
formatter("span", style = x ~ ifelse(substring(x, 1, 5) == "Above",
style(color = "red",
font.weight = "bold"),
NA))))
return (outputTable)
}
"Function that returns a sortable table which contains weekly deaths, expected
deaths and excess deaths according to agegroup and gender"
longTable <- function() {
outputtable <- datatable(longTable_data,
colnames = c("Gender",
"Agegroup",
"Week",
"Country",
"Deaths",
"Expected Deaths",
"Excess Deaths"),
filter = "top",
options = list(pageLength = 20, autoWidth = TRUE),
class = 'cell-border stripe'
)
return (outputtable)
}
save(longTable_data, file = "Shiny/data/longTable_data.Rda")
save(totaldata, file = "Shiny/data/totaldata.Rda")
detectCOres()
######################### ML script/prediction script #################################
"Support for utf-8 encoding"
options(encoding="utf-8")
"Libraries"
library(caret)
library(dplyr)
library(magrittr)
library(gbm)
library(docstring)
library(doParallel)
detectCores()
######################### ML script/prediction script #################################
"Support for utf-8 encoding"
options(encoding="utf-8")
"Libraries"
library(caret)
library(dplyr)
library(magrittr)
library(gbm)
library(docstring)
library(doParallel)
"Loading data frames retrieved from standardisation.r"
load("../datasett/processed_data_all_countries.Rda")
"load totaldata"
load("Shiny/data/totaldata.Rda")
aggregateAgegroup <- function() {
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
group_by(week, year, gender, country) %>%
summarise(deaths = sum(deaths),
expected_deaths = sum(expected_deaths),
excess_deaths = sum(excess_deaths))
}
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
select(country, week, gender, agegroup, deaths, excess_deaths)
intrain <- createDataPartition(y = totaldata$excess_deaths,
p = 0.8,
list = FALSE)
training_data <- totaldata[intrain,] #%>% select(excess_deaths,week)
test_data     <- totaldata[-intrain,]
.f <- function() {
gbmModel <- train(excess_deaths ~.,
distribution = "bernoulli",
data = training_data,
n.trees = 500,
interaction.depth = 4,
shrinkage = 0.01)
}
## Make a model-----------------------------------------
linnearreg <- train(excess_deaths ~ week,
data = training_data,
method = "lm")
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf")
print(linnearreg)
summary(linnearreg)
print(RFmodel)
### Prediction #--------------------------
predict(linearreg, test_data)
predict(RFmodel, newdata = head(test_data), type = "prob")
predict(RFmodel, newdata = head(test_data))
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf",
trcontrol = fitcontrol)
stopclsuter(cl) #Stop cluster
#Print relevant statistics
print(linnearreg)
summary(linnearreg)
print(RFmodel)
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf",
trcontrol = fitcontrol)
stopclsuter(cl) #Stop cluster
#Print relevant statistics
print(linnearreg)
summary(linnearreg)
print(RFmodel)
######################### ML script/prediction script #################################
"Support for utf-8 encoding"
options(encoding="utf-8")
"Libraries"
library(caret)
library(dplyr)
library(magrittr)
library(gbm)
library(docstring)
library(doParallel)
"Loading data frames retrieved from standardisation.r"
load("../datasett/processed_data_all_countries.Rda")
"load totaldata"
load("Shiny/data/totaldata.Rda")
aggregateAgegroup <- function() {
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
group_by(week, year, gender, country) %>%
summarise(deaths = sum(deaths),
expected_deaths = sum(expected_deaths),
excess_deaths = sum(excess_deaths))
}
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
select(country, week, gender, agegroup, deaths, excess_deaths)
intrain <- createDataPartition(y = totaldata$excess_deaths,
p = 0.8,
list = FALSE)
training_data <- totaldata[intrain,] #%>% select(excess_deaths,week)
test_data     <- totaldata[-intrain,]
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf",
trcontrol = fitcontrol)
#Print relevant statistics
print(linnearreg)
summary(linnearreg)
print(RFmodel)
######################### ML script/prediction script #################################
"Support for utf-8 encoding"
options(encoding="utf-8")
"Libraries"
library(caret)
library(dplyr)
library(magrittr)
library(gbm)
library(docstring)
library(doParallel)
"Loading data frames retrieved from standardisation.r"
load("../datasett/processed_data_all_countries.Rda")
"load totaldata"
load("Shiny/data/totaldata.Rda")
aggregateAgegroup <- function() {
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
group_by(week, year, gender, country) %>%
summarise(deaths = sum(deaths),
expected_deaths = sum(expected_deaths),
excess_deaths = sum(excess_deaths))
}
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
select(country, week, gender, agegroup, deaths, excess_deaths)
intrain <- createDataPartition(y = totaldata$excess_deaths,
p = 0.8,
list = FALSE)
training_data <- totaldata[intrain,] #%>% select(excess_deaths,week)
test_data     <- totaldata[-intrain,]
.f <- function() {
gbmModel <- train(excess_deaths ~.,
distribution = "bernoulli",
data = training_data,
n.trees = 500,
interaction.depth = 4,
shrinkage = 0.01)
}
## Model creation -----------------------------------------
#Make clusters
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)
#
linnearreg <- train(excess_deaths ~ week,
data = training_data,
method = "lm")
control <- train(method = "rf",
n = 10,
repeats = 10)
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf",
trcontrol = control)
#Print relevant statistics
print(linnearreg)
summary(linnearreg)
print(RFmodel)
stopclsuter(cl) #Stop cluster
### Prediction #---------------------------------------------
predict(linearreg, test_data)
predict(RFmodel, newdata = head(test_data))
control <- trainControl(method = "rf",
n = 10,
repeats = 10)
######################### ML script/prediction script #################################
"Support for utf-8 encoding"
options(encoding="utf-8")
"Libraries"
library(caret)
library(dplyr)
library(magrittr)
library(gbm)
library(docstring)
library(doParallel)
"Loading data frames retrieved from standardisation.r"
load("../datasett/processed_data_all_countries.Rda")
"load totaldata"
load("Shiny/data/totaldata.Rda")
aggregateAgegroup <- function() {
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
group_by(week, year, gender, country) %>%
summarise(deaths = sum(deaths),
expected_deaths = sum(expected_deaths),
excess_deaths = sum(excess_deaths))
}
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
select(country, week, gender, agegroup, deaths, excess_deaths)
intrain <- createDataPartition(y = totaldata$excess_deaths,
p = 0.8,
list = FALSE)
training_data <- totaldata[intrain,] #%>% select(excess_deaths,week)
test_data     <- totaldata[-intrain,]
.f <- function() {
gbmModel <- train(excess_deaths ~.,
distribution = "bernoulli",
data = training_data,
n.trees = 500,
interaction.depth = 4,
shrinkage = 0.01)
}
## Model creation -----------------------------------------
#Make clusters
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)
#
linnearreg <- train(excess_deaths ~ week,
data = training_data,
method = "lm")
control <- trainControl(method = "rf",
n = 10,
repeats = 10)
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf",
trcontrol = control)
#Print relevant statistics
print(linnearreg)
summary(linnearreg)
print(RFmodel)
stopclsuter(cl) #Stop cluster
### Prediction #---------------------------------------------
predict(linearreg, test_data)
predict(RFmodel, newdata = head(test_data))
plot(RFmodel)
View(test_data)
View(totaldata)
colnames(test_data)
help(train)
getModelinfo(RFmodel)
getModelInfo(RFmodel)
help(predict)
postResample(pred = rfPrediction, obs = test_data$excess_deaths) #Evaluate
rfPrediction <- predict(RFmodel, newdata = testdata)
rfPrediction <- predict(RFmodel, newdata = test_data)
postResample(pred = rfPrediction, obs = test_data$excess_deaths) #Evaluate
######################### ML script/prediction script #################################
"Support for utf-8 encoding"
options(encoding="utf-8")
"Libraries"
library(caret)
library(dplyr)
library(magrittr)
library(gbm)
library(docstring)
library(doParallel)
"Loading data frames retrieved from standardisation.r"
load("../datasett/processed_data_all_countries.Rda")
"load totaldata"
load("Shiny/data/totaldata.Rda")
#### Data selection --------------------------------------------
aggregateAgegroup <- function() {
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
group_by(week, year, gender, country) %>%
summarise(deaths = sum(deaths),
expected_deaths = sum(expected_deaths),
excess_deaths = sum(excess_deaths))
}
totaldata %<>%
transform(week = as.factor(week),
country = as.factor(country),
year   = as.factor(year)) %>%
select(country, week, gender, agegroup, deaths, excess_deaths)
intrain <- createDataPartition(y = totaldata$excess_deaths,
p = 0.8,
list = FALSE)
# Splitting data ---------------------------------------------
training_data <- totaldata[intrain,] #%>% select(excess_deaths,week)
test_data     <- totaldata[-intrain,]
## Model creation -----------------------------------------
#Make clusters
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)
#
linnearreg <- train(excess_deaths ~ week,
data = training_data,
method = "lm")
control <- trainControl(method = "repeatedcv",
n = 10,
repeats = 5)
RFmodel <- train(excess_deaths ~.,
data = training_data,
method = "rf",
metric = "RMSE",
trcontrol = control)
#Print relevant statistics
print(linnearreg)
summary(linnearreg)
print(RFmodel)
stopCluster(cl) #Stop cluster
get_predicted_score <- function(model = RFmodel, week,gender,agegroup,deaths){
df <-
data.frame(
week = as.factor(week),
gender = as.factor(gender),
agegroup = as.factor(agegroup),
deaths = as.numeric(deaths)
)
print(df)
#df <- totaldata
#data.frame(
# scoring_date = as.Date(Sys.Date()),
#prob =
#   predict(
#    model,
#   newdat = df,
#    type = "prob")$Default)
}
get_predicted_score(week = 1, gender = "F", agegroup = "0-64", deaths = 20)
